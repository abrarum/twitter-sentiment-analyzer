{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the function \"load_train_test_imdb_data\" and try to understand what is it doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_train_test_imdb_data(data_dir):\n",
    "    \"\"\"Loads the IMDB train/test datasets from a folder path.\n",
    "    Input:\n",
    "    data_dir: path to the \"aclImdb\" folder.\n",
    "    \n",
    "    Returns:\n",
    "    train/test datasets as pandas dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        data[split] = []\n",
    "        for sentiment in [\"neg\", \"pos\"]:\n",
    "            score = 1 if sentiment == \"pos\" else 0\n",
    "\n",
    "            path = os.path.join(data_dir, split, sentiment)\n",
    "            file_names = os.listdir(path)\n",
    "            for f_name in file_names:\n",
    "                with open(os.path.join(path, f_name), \"r\") as f:\n",
    "                    review = f.read()\n",
    "                    data[split].append([review, score])\n",
    "\n",
    "    np.random.shuffle(data[\"train\"])        \n",
    "    data[\"train\"] = pd.DataFrame(data[\"train\"],\n",
    "                                 columns=['text', 'sentiment'])\n",
    "\n",
    "    np.random.shuffle(data[\"test\"])\n",
    "    data[\"test\"] = pd.DataFrame(data[\"test\"],\n",
    "                                columns=['text', 'sentiment'])\n",
    "\n",
    "    return data[\"train\"], data[\"test\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function \"load_train_test_imdb_data\" to load the data. Use the variable names \"train_data\" and \"test_data\". \n",
    "To load the data, you have to indicate the path to the data folder. If you are using the jupiter server, use the path \"/mnt/nvs3/nlp-public/aclImdb/\". If you are using jupiter notebook on your own computer, download the data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz and extract it (you can use the command \"tar -zxvf aclImdb_v1.tar.gz\" on a Unix system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the train and test data in train_data and test_data\n",
    "path = \"/mnt/nvs3/nlp-public/aclImdb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 5 rows of the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print first 5 rows of train data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 5 rows of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print first 5 elements of test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the information about the train_data dataframe. You can use the function \"info()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print info for dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform each text into a vector of word counts. Use the class \"CountVectorizer\" with an attribute \"stop_words=\"english\"\". To create the training features use the method \"fit_transform()\". To create the test features use the method \"transform()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Transform each text into a vector of word counts\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "training_features =    \n",
    "test_features = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the features' names. To do that use the method \"get_feature_names()\" from \"CountVectorizer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the features' names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the dimentions of the training and the test data features. Use the property \"shape\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print training data dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print test data dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a SVM model using the class \"LinearSVC\". Use the \"fit()\" function to train the model. It takes as parameters the training_features, and the annotation form the training data. Make prediction with the trained model using the \"predict()\" function. The function takes as an input the test_features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Training with linear SVM\n",
    "model = #define the model\n",
    "        #fit the model\n",
    "y_pred = #predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the persformance of the model: confusion matrix, using the function \"confusion_matrix()\"; accuracy, using the function \"accuracy_score()\"; precision, using the function \"precision_score\"; recall, using the function \"recall_score\"; and F1 score, using the function \"f1_score\". Use the function \"classification_report()\" to calculate all metrics. Print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#Calculate performance\n",
    "conf =  #confusion matrix\n",
    "\n",
    "    #print confusion matrix\n",
    "    \n",
    "acc =  #accuracy\n",
    "\n",
    "    #print accuracy\n",
    "\n",
    "prec =  #precision\n",
    "\n",
    "    #print precision\n",
    "\n",
    "rec =  #recall\n",
    "\n",
    "    #print recall\n",
    "\n",
    "f1 =  #f1\n",
    "\n",
    "    #print f1 score\n",
    "\n",
    "rep =  #generates a report for precision, recall, f1-score and support\n",
    "\n",
    "    #print report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree model using the class \"DecisionTreeClassifier\". Use the \"fit()\" function to train the model. It takes as parameters the training_features, and the annotation form the training data. Make prediction with the trained model using the \"predict()\" function. The function takes as an input the test_features. Print the maximum depth of the tree. To do that use the property \"tree_.max_depth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Training with decision tree\n",
    "model = #define the model\n",
    "    #fit the model\n",
    "y_predDT = #predict on new data\n",
    "\n",
    "    #print max depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the SVM, print the performance metrics for the DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate performance\n",
    "\n",
    "conf =  #confusion matrix\n",
    "\n",
    "    #print confusion matrix\n",
    "    \n",
    "acc =  #accuracy\n",
    "\n",
    "    #print accuracy\n",
    "\n",
    "prec =  #precision\n",
    "\n",
    "    #print precision\n",
    "\n",
    "rec =  #recall\n",
    "\n",
    "    #print recall\n",
    "\n",
    "f1 =  #f1\n",
    "\n",
    "    #print f1 score\n",
    "\n",
    "rep =  #generates a report for precision, recall, f1-score and support\n",
    "\n",
    "    #print report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the decision tree model by limiting the maximum tree depth to 10. You can do that by using the attribute \"max_depth\" in \"DecisionTreeClassifier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with decision tree with max depth\n",
    "model = #define the model\n",
    "    #fit the model\n",
    "y_predDT = #predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, calculate the performance metrics and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate performance\n",
    "conf =  #confusion matrix\n",
    "\n",
    "    #print confusion matrix\n",
    "    \n",
    "acc =  #accuracy\n",
    "\n",
    "    #print accuracy\n",
    "\n",
    "prec =  #precision\n",
    "\n",
    "    #print precision\n",
    "\n",
    "rec =  #recall\n",
    "\n",
    "    #print recall\n",
    "\n",
    "f1 =  #f1\n",
    "\n",
    "    #print f1 score\n",
    "\n",
    "rep =  #generates a report for precision, recall, f1-score and support\n",
    "\n",
    "    #print report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from sklearn import tree\n",
    "from IPython.display import display\n",
    "\n",
    "#display DT tree\n",
    "graph = Source(tree.export_graphviz(model, out_file=None\n",
    "   , class_names=['0', '1'] \n",
    "   , filled = True))\n",
    "\n",
    "display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
